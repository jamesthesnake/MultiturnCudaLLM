# Configuration for 3x A40 CUDA RL System

# GPU Configuration
gpu:
  num_gpus: 3
  model_gpu: 0
  kernel_gpus: [1, 2]
  memory_fraction: 0.8
  device_type: "A40"
  compute_capability: "8.6"

# Model Configuration
model:
  name: "deepseek-ai/deepseek-coder-1.3b-base"
  # Alternative smaller model for testing
  # name: "microsoft/codebert-base"
  dtype: "float16"
  max_length: 2048
  temperature: 1.0

# Training Configuration
training:
  # GRPO settings
  group_size: 4
  group_batch_size: 64  # Increased for 3x A40s
  learning_rate: 1.0e-6
  kl_penalty: 0.005
  epsilon_cur: 0.5
  
  # Optimization settings
  num_steps: 1000
  eval_interval: 50
  save_interval: 100
  
  # Multi-turn settings
  max_turns: 4
  turn_bonuses:
    1:
      memory_coalescing: 0.15
      tiling: 0.2
    2:
      shared_memory: 0.3
      synchronization: 0.1
    3:
      bank_conflict: 0.25
      register_blocking: 0.2
    4:
      tensor_cores: 0.4

# Search Configuration
search:
  # Beam search settings
  beam_width: 8
  num_candidates: 16
  
  # MCTS settings
  num_simulations: 100
  c_param: 1.414

# Kernel Evaluation
evaluation:
  compile_timeout: 30
  run_timeout: 10
  max_parallel_evals: 2  # One per kernel GPU
  
  # A40-specific compilation flags
  nvcc_flags:
    - "-O3"
    - "-arch=sm_86"
    - "-use_fast_math"
    - "--extra-device-vectorization"

# Curriculum Learning
curriculum:
  buffer_capacity: 10000
  variance_threshold: 0.1
  seed_from_previous: true

# Experiment Tracking
tracking:
  use_wandb: true
  project_name: "cuda-rl-3xa40"
  save_code: true
  log_gradients: false

# System Configuration
system:
  # Process pool for CPU compilation
  compile_workers: 4
  
  # Async settings
  max_concurrent_evaluations: 4
  
  # Memory management
  clear_cache_interval: 50  # Clear GPU cache every N steps
  
  # Monitoring
  log_gpu_stats: true
  stats_interval: 10

# Dataset Configuration
dataset:
  types: ["gemm", "conv", "reduction"]
  synthetic_kernels: true
  kernelbench_path: "~/KernelBench"
  
  # Problem sizes for GEMM
  gemm_sizes:
    small: [128, 256, 512]
    medium: [1024, 2048]
    large: [4096, 8192]

# Environment Variables
env:
  CUDA_LAUNCH_BLOCKING: "0"
  TORCH_CUDA_ARCH_LIST: "8.6"
  CUBLAS_WORKSPACE_CONFIG: ":4096:8"
  OMP_NUM_THREADS: "4"
  MKL_NUM_THREADS: "4"
